---
title: "Assignment-3"
author: "Shubhangi Srivastava"
date: "26/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 14. This problem focuses on the collinearity problem.

### 14(a) Perform the following commands in R:The last line corresponds to creating a linear model in which y is a function of x1 and x2. Write out the form of the linear model. What are the regression coefficients?

```{r A, echo=TRUE}
set.seed(1)
x1 = runif(100)
x2 = 0.5 * x1 + rnorm(100)/10
y = 2 + 2*x1 + 0.3*x2 + rnorm(100)
```

**The regression coefficients are βo = 2+rnorm(100), β1 = 2, and β2 = 0.3**


### 14(b) What is the correlation between x1 and x2? Create a scatterplot displaying the relationship between the variables.

```{r B, echo=TRUE}
cor(x1, x2)
plot(x1, x2)
```

### 14(c) Using this data, fit a least squares regression to predict y using x1 and x2. Describe the results obtained. What are βˆ0, βˆ1, and βˆ2? How do these relate to the true β0, β1, and β2? Can you reject the null hypothesis H0 : β1 = 0? How about the null hypothesis H0 : β2 = 0?

```{r C, echo=TRUE}
lm.fit =lm(y~x1+x2)
summary(lm.fit)
```
**Interpretations from output :**
**β0=2.0533,β1=1.6336,β2=0.5588**
**The regression coefficients are close to the true coefficients, although with high standard error. We can reject the null hypothesis for β1 because its p-value is below 5%. We cannot reject the null hypothesis for β2 because its p-value is much above the 5%.**



### 14(d) Now fit a least squares regression to predict y using only x1. Comment on your results. Can you reject the null hypothesis H0 :β1 =0?
```{r D, echo=TRUE}
lm.fit = lm(y~x1)
summary(lm.fit)
```
**Interpretations from output :**
**Yes, we can reject the null hypothesis for the regression coefficient given the p-value for its t-statistic is near zero**



### 14(e) Now fit a least squares regression to predict y using only x2. Comment on your results. Can you reject the null hypothesis H0 :β1 =0?
```{r E, echo=TRUE}
lm.fit = lm(y~x2)
summary(lm.fit)
```
**Interpretations from output :**
**Yes, we can reject the null hypothesis for the regression coefficient given the p-value for its t-statistic is near zero.**


### 14(f) Do the results obtained in (c)–(e) contradict each other? Explain your answer.

**Interpretations from output :**
**x1 and x2 have collinearity, it is hard to distinguish their effects when regressed upon together. When they are regressed upon separately, the linear relationship between y and each predictor is indicated more clearly.In part-c,we discarded x1 and x2 as significant predictor variables.In part-e, separate linear regression models with each of the predictors show that x1 and x2 are actually quite significant.**



### 10. This question should be answered using the Weekly data set, which is part of the ISLR package. This data is similar in nature to the Smarket data from this chapter’s lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010.


### 10(a) Produce some numerical and graphical summaries of the Weekly data. Do there appear to be any patterns?
```{r AA, echo=TRUE}
library(ISLR)
summary(Weekly)
pairs(Weekly)
cor(Weekly[, -9])
```
**Interpretations from output :**
**We can see a relationship between "Year" and "Volume".No other patterns are observed .**



### 10(b) Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?
```{r BB, echo=TRUE}
attach(Weekly)
glm.fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, 
              family = binomial)
summary(glm.fit)
```
**Interpretations from output :**
**Lag 2 appears to have some statistical significance with a p value of 3 % which is less than 5 %**


### 10(c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.
```{r CC, echo=TRUE}
glm.probs = predict(glm.fit, type = "response")
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
```
**Interpretations from output :**
**currect predictions: (54+557)/(54+557+48+430) = 56.1%. **
**When logistic regression is right: 557/(557+48) = 92.1%.**
**When logistic regression is wrong: 54/(430+54) = 11.2%.**



### 10(d) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010).

```{r DD, echo=TRUE}
train = (Year < 2009)
Weekly.0910 = Weekly[!train, ]
glm.fit = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fit, Weekly.0910, type = "response")
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
Direction.0910 = Direction[!train]
table(glm.pred, Direction.0910)

mean(glm.pred == Direction.0910)
```


### 10(e) Repeat (d) using LDA.
```{r EE, echo=TRUE}
library(MASS)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.pred = predict(lda.fit, Weekly.0910)
table(lda.pred$class, Direction.0910)

mean(lda.pred$class == Direction.0910)

```


### 10(f) Repeat (d) using QDA.

```{r FF, echo=TRUE}
library(MASS)
qda.fit = qda(Direction ~ Lag2, data = Weekly, subset = train)
qda.class = predict(qda.fit, Weekly.0910)$class
table(qda.class, Direction.0910)

mean(qda.class == Direction.0910)
```
**Interpretations from output :**
**Accuracy of 58.7% even though it picked Up the whole time!**



### 10(g) Repeat (d) using KNN with K = 1.

```{r GG, echo=TRUE}
library(class)
train.X = as.matrix(Lag2[train])
test.X = as.matrix(Lag2[!train])
train.Direction = Direction[train]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.0910)

mean(knn.pred == Direction.0910)

```


### 10(h) Which of these methods appears to provide the best results on this data?

**Interpretations from output :**
**Logistic regression and LDA methods provide similar test error rates.**

### 10(i) Experiment with different combinations of predictors, includ- ing possible transformations and interactions, for each of the methods. Report the variables, method, and associated confu- sion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for K in the KNN classifier.

```{r II, echo=TRUE}
# Logistic regression with Lag2:Lag1
glm.fit = glm(Direction ~ Lag2:Lag1, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fit, Weekly.0910, type = "response")
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
Direction.0910 = Direction[!train]
table(glm.pred, Direction.0910)

mean(glm.pred == Direction.0910)

# LDA with Lag2 interaction with Lag1
lda.fit = lda(Direction ~ Lag2:Lag1, data = Weekly, subset = train)
lda.pred = predict(lda.fit, Weekly.0910)

mean(lda.pred$class == Direction.0910)

# QDA with sqrt(abs(Lag2))
qda.fit = qda(Direction ~ Lag2 + sqrt(abs(Lag2)), data = Weekly, subset = train)
qda.class = predict(qda.fit, Weekly.0910)$class
table(qda.class, Direction.0910)

mean(qda.class == Direction.0910)

# KNN k =10
knn.pred = knn(train.X, test.X, train.Direction, k = 10)
mean(knn.pred == Direction.0910)

# KNN k = 100
knn.pred = knn(train.X, test.X, train.Direction, k = 100)
table(knn.pred, Direction.0910)

mean(knn.pred == Direction.0910)

# Out of all combinations tried the original LDA and logistic regression have better performance in terms of test error rate.

table(knn.pred, Direction.0910)
```
